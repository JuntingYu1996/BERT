{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "colab_type": "code",
    "id": "n37RJPCWEM3W",
    "outputId": "6ab65655-c4be-455d-f84d-edf189a448db"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1048565</td>\n",
       "      <td>Sentence: 47958</td>\n",
       "      <td>impact</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1048566</td>\n",
       "      <td>Sentence: 47958</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1048567</td>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>Indian</td>\n",
       "      <td>JJ</td>\n",
       "      <td>B-gpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1048568</td>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>forces</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1048569</td>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>said</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1048570</td>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>they</td>\n",
       "      <td>PRP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1048571</td>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>responded</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1048572</td>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1048573</td>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1048574</td>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>attack</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Sentence #       Word  POS    Tag\n",
       "1048565  Sentence: 47958     impact   NN      O\n",
       "1048566  Sentence: 47958          .    .      O\n",
       "1048567  Sentence: 47959     Indian   JJ  B-gpe\n",
       "1048568  Sentence: 47959     forces  NNS      O\n",
       "1048569  Sentence: 47959       said  VBD      O\n",
       "1048570  Sentence: 47959       they  PRP      O\n",
       "1048571  Sentence: 47959  responded  VBD      O\n",
       "1048572  Sentence: 47959         to   TO      O\n",
       "1048573  Sentence: 47959        the   DT      O\n",
       "1048574  Sentence: 47959     attack   NN      O"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "csv_file = \"https://raw.githubusercontent.com/JuntingYu1996/BERT/master/ner_dataset.csv\"\n",
    "encoding = \"latin1\"\n",
    "sep = \",\"\n",
    "# quoting = csv.QUOTE_NONE\n",
    "quoting = 0\n",
    "\n",
    "data = pd.read_csv(csv_file,sep=sep,encoding=encoding,quoting=quoting).fillna(method=\"ffill\")\n",
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7gj-Va_rEM3b"
   },
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                           s[\"POS\"].values.tolist(),\n",
    "                                                           s[\"Tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wr0rAWR-EM3d"
   },
   "outputs": [],
   "source": [
    "getter = SentenceGetter(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ApBg4tfDEM3f",
    "outputId": "41ce9725-8929-4698-a1a4-92bc234c8076"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .'"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [\" \".join([s[0] for s in sent]) for sent in getter.sentences]\n",
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mN-bp_tJEM3h"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
    "from pytorch_pretrained_bert import BertForTokenClassification, BertAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lieovOfLEM3r"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 75 # maximum number of tokens in a sequence\n",
    "bs = 32 # batch size\n",
    "BERT_MAX_LEN = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DoyT63NLEM3t"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U84lpKchEM3v"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e_8qQ5FjEM3y"
   },
   "outputs": [],
   "source": [
    "# tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "tokenized_texts = []\n",
    "labels = [[s[2] for s in sent] for sent in getter.sentences]\n",
    "for sent in range(len(sentences)):\n",
    "    tokenized_texts.append([])\n",
    "    splitted = sentences[sent].split()\n",
    "    for word in range(len(splitted)):\n",
    "        for padding in range(len(tokenizer.tokenize(splitted[word])) - 1):\n",
    "            labels[sent].insert(len(tokenized_texts[-1])+padding+1,'X')\n",
    "        tokenized_texts[-1].extend(tokenizer.tokenize(splitted[word]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "colab_type": "code",
    "id": "rKqqMTG7EM30",
    "outputId": "0525c557-6b81-452d-bf3e-c93e00851012"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking sentence 10226\n",
      "Lieutenant Nathan Perry Monday told VOA that U.S. helicopters did not enter \n",
      "\n",
      "['lieutenant', 'nathan', 'perry', 'monday', 'told', 'vo', '##a', 'that', 'u', '.', 's', '.', 'helicopters', 'did', 'not', 'enter'] \n",
      "\n",
      "Length of tokenized text: 16\n",
      "\n",
      "['O', 'B-per', 'I-per', 'B-tim', 'O', 'B-org', 'X', 'O', 'B-geo', 'X', 'X', 'X', 'O', 'O', 'O', 'O'] \n",
      "\n",
      "Length of labels: 16\n",
      "\n",
      "nathan : B-per\n",
      "perry : I-per\n",
      "monday : B-tim\n",
      "vo : B-org\n",
      "##a : X\n",
      "u : B-geo\n",
      ". : X\n",
      "s : X\n",
      ". : X\n"
     ]
    }
   ],
   "source": [
    "checking = np.random.randint(len(tokenized_texts))\n",
    "print(\"Checking sentence %d\"%checking)\n",
    "print(sentences[checking],\"\\n\")\n",
    "print(tokenized_texts[checking],'\\n')\n",
    "print(\"Length of tokenized text: %d\\n\"%len(tokenized_texts[checking]))\n",
    "print(labels[checking],'\\n')\n",
    "print(\"Length of labels: %d\\n\"%len(labels[checking]))\n",
    "for token in range(len(tokenized_texts[checking])):\n",
    "    if labels[checking][token]!='O':\n",
    "      print(tokenized_texts[checking][token]+\" : \"+labels[checking][token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "y0-bi3xMEM32",
    "outputId": "a1ce8e8d-624f-46f4-91f2-941ff7eb80e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'I-art': 0, 'B-art': 1, 'I-per': 2, 'B-eve': 3, 'B-tim': 4, 'I-gpe': 5, 'B-org': 6, 'I-tim': 7, 'I-org': 8, 'I-eve': 9, 'O': 10, 'B-per': 11, 'B-geo': 12, 'B-gpe': 13, 'B-nat': 14, 'I-geo': 15, 'I-nat': 16, 'X': 17}\n",
      "{0: 'I-art', 1: 'B-art', 2: 'I-per', 3: 'B-eve', 4: 'B-tim', 5: 'I-gpe', 6: 'B-org', 7: 'I-tim', 8: 'I-org', 9: 'I-eve', 10: 'O', 11: 'B-per', 12: 'B-geo', 13: 'B-gpe', 14: 'B-nat', 15: 'I-geo', 16: 'I-nat', 17: 'X'}\n"
     ]
    }
   ],
   "source": [
    "tags_vals = list(set(data[\"Tag\"].values))\n",
    "tags_vals.append('X')\n",
    "tag2idx = {t: i for i, t in enumerate(tags_vals)}\n",
    "print(tag2idx)\n",
    "idx2tag = {tag2idx[t]: t for t in tag2idx.keys()}\n",
    "print(idx2tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-Amenity',\n",
       " 'B-Cuisine',\n",
       " 'B-Dish',\n",
       " 'B-Hours',\n",
       " 'B-Location',\n",
       " 'B-Price',\n",
       " 'B-Rating',\n",
       " 'B-Restaurant_Name',\n",
       " 'I-Amenity',\n",
       " 'I-Cuisine',\n",
       " 'I-Dish',\n",
       " 'I-Hours',\n",
       " 'I-Location',\n",
       " 'I-Price',\n",
       " 'I-Rating',\n",
       " 'I-Restaurant_Name',\n",
       " 'O',\n",
       " 'X']"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(tag2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5YsTFzueEM34"
   },
   "outputs": [],
   "source": [
    "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
    "                          maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aOQbSmLrEM39"
   },
   "outputs": [],
   "source": [
    "tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels],\n",
    "                     maxlen=MAX_LEN, value=tag2idx[\"O\"], padding=\"post\",\n",
    "                     dtype=\"long\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wOXlbsZbEM3_"
   },
   "outputs": [],
   "source": [
    "attention_masks = [[float(i>0) for i in ii] for ii in input_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0myy_wZlEM4B"
   },
   "outputs": [],
   "source": [
    "tr_inputs, val_inputs, tr_tags, val_tags = train_test_split(input_ids, tags, random_state=2020, test_size=0.3)\n",
    "tr_masks, val_masks, _, _ = train_test_split(attention_masks, input_ids, random_state=2020, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "colab_type": "code",
    "id": "G5jEBKhoEM4D",
    "outputId": "72d5af90-71ee-40fc-d214-01e8754ca229"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['there', 'are', 'precedent', '##s', 'of', 'independent', 'governors', 'dealing', 'effectively', 'with', 'the', 'legislature', ',', 'and', 'indeed', 'a', 'wise', 'third', '-', 'party', 'governor', 'can', 'have', 'greater', 'effectiveness', 'than', 'a', 'major', 'party', 'governor', '.'] \n",
      "\n",
      "precedent: B-abstract \n",
      "##s: X \n",
      "of: I-abstract \n",
      "independent: I-abstract \n",
      "governors: I-abstract \n",
      "the: B-organization \n",
      "legislature: I-organization \n",
      "a: B-person \n",
      "wise: I-person \n",
      "third: I-person \n",
      "-: X \n",
      "party: X \n",
      "governor: I-person \n",
      "greater: B-abstract \n",
      "effectiveness: I-abstract \n",
      "a: B-person \n",
      "major: I-person \n",
      "party: I-person \n",
      "governor: I-person \n"
     ]
    }
   ],
   "source": [
    "#random checking\n",
    "\n",
    "checking = np.random.randint(val_inputs.shape[0])\n",
    "decoded_tokens = tokenizer.convert_ids_to_tokens(np.array((val_inputs[checking])))\n",
    "decoded_tokens = [word for word in decoded_tokens if word != '[PAD]']\n",
    "print(decoded_tokens,\"\\n\")\n",
    "for word in range(len(decoded_tokens)):\n",
    "    if val_tags[checking][word]!=tag2idx['O']:\n",
    "        print(\"%s: %s \"%(decoded_tokens[word],idx2tag[np.int(val_tags[checking][word])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TWV5Jm0kEM4F"
   },
   "outputs": [],
   "source": [
    "tr_inputs = torch.tensor(tr_inputs)\n",
    "val_inputs = torch.tensor(val_inputs)\n",
    "tr_tags = torch.tensor(tr_tags)\n",
    "val_tags = torch.tensor(val_tags)\n",
    "tr_masks = torch.tensor(tr_masks)\n",
    "val_masks = torch.tensor(val_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ATXaPgl3EM4H"
   },
   "outputs": [],
   "source": [
    "train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=bs)\n",
    "\n",
    "valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
    "valid_sampler = SequentialSampler(valid_data)\n",
    "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RVl1I3uREM4J"
   },
   "outputs": [],
   "source": [
    "model = BertForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(tag2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "MrHwlJKbEM4O",
    "outputId": "588b8887-96f7-4a50-84ed-39a7e1c40a85"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=24, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 95,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mmwk5TvjEM4T"
   },
   "outputs": [],
   "source": [
    "FULL_FINETUNING = True\n",
    "if FULL_FINETUNING:\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'gamma', 'beta']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.0}\n",
    "    ]\n",
    "else:\n",
    "    param_optimizer = list(model.classifier.named_parameters()) \n",
    "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
    "optimizer = Adam(optimizer_grouped_parameters, lr=3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_jW9CdPlEM4X"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=2).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y365uBwZwDHG"
   },
   "outputs": [],
   "source": [
    "# checking whether loss is equal when active labels contain 'X' or not\n",
    "# loss_fct = torch.nn.CrossEntropyLoss(ignore_index=tag2idx['X'])\n",
    "# checking = np.random.randint(tr_inputs.shape[0])\n",
    "# b_input_ids, b_input_mask, b_labels = tr_inputs[checking:checking+1].to(device),tr_masks[checking:checking+1].to(device),tr_tags[checking:checking+1].to(device)\n",
    "# decoded_tokens = tokenizer.convert_ids_to_tokens(np.array((tr_inputs[checking])))\n",
    "# decoded_tokens = [word for word in decoded_tokens if word != '[PAD]']\n",
    "# print(decoded_tokens,\"\\n\")\n",
    "# active = ((b_input_mask.view(-1) == 1) * (b_labels.view(-1) != tag2idx['X']))\n",
    "# logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "# active_logits = logits.view(-1, len(tag2idx))[active]\n",
    "# active_labels = b_labels.view(-1)[active]\n",
    "# print(active_labels)\n",
    "# loss = loss_fct(active_logits, active_labels)\n",
    "# print(loss.item())\n",
    "\n",
    "\n",
    "# active = (b_input_mask.view(-1) == 1)\n",
    "# logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "# active_logits = logits.view(-1, len(tag2idx))[active]\n",
    "# active_labels = b_labels.view(-1)[active]\n",
    "# print(active_labels)\n",
    "# loss = loss_fct(active_logits, active_labels)\n",
    "# print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "pxgA25PL8iP5",
    "outputId": "80e8b11b-bc52-476c-bfc1-e8176a5c69ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 0.])\n"
     ]
    }
   ],
   "source": [
    "weight_fct = lambda num: 1\n",
    "weight = np.array([weight_fct(np.sum(tags == i)) for i in range(len(tag2idx))],dtype=float)\n",
    "weight[tag2idx['X']] = 0\n",
    "weight = torch.tensor(weight).to(torch.float)\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "5lrOw2O_EM4a",
    "outputId": "e858284b-d3ea-408f-f7d4-8a6f9431101a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "\n",
      "Epoch:   2%|▏         | 1/50 [00:29<23:56, 29.32s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.214677738420891\n",
      "Validation loss: 1.2712256095626138\n",
      "Validation Accuracy: 0.633559598153679\n",
      "F1-Score: 0.21851146695874962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:   4%|▍         | 2/50 [00:58<23:27, 29.33s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.5252207680182024\n",
      "Validation loss: 0.9748769059325709\n",
      "Validation Accuracy: 0.7186532717893022\n",
      "F1-Score: 0.4580010899097184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:   6%|▌         | 3/50 [01:27<22:55, 29.26s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.8397673693570225\n",
      "Validation loss: 0.9261372053261959\n",
      "Validation Accuracy: 0.7323377681238121\n",
      "F1-Score: 0.5428055428820568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:   8%|▊         | 4/50 [01:57<22:26, 29.27s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.3914752250367945\n",
      "Validation loss: 0.9271842241287231\n",
      "Validation Accuracy: 0.7376595166983437\n",
      "F1-Score: 0.6057812307697468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  10%|█         | 5/50 [02:26<21:58, 29.29s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.0175983147187666\n",
      "Validation loss: 1.0059846784129287\n",
      "Validation Accuracy: 0.7426011403746945\n",
      "F1-Score: 0.6189257653654494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  12%|█▏        | 6/50 [02:55<21:26, 29.24s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7294880467833895\n",
      "Validation loss: 1.0462872115048496\n",
      "Validation Accuracy: 0.7490632636437686\n",
      "F1-Score: 0.6255317366938133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  14%|█▍        | 7/50 [03:24<20:57, 29.24s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.548250515352596\n",
      "Validation loss: 1.133968629620292\n",
      "Validation Accuracy: 0.7480314960629921\n",
      "F1-Score: 0.6183430600262756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  16%|█▌        | 8/50 [03:53<20:26, 29.20s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.4094369499520822\n",
      "Validation loss: 1.1946092356335034\n",
      "Validation Accuracy: 0.7451534075481944\n",
      "F1-Score: 0.6186411387752279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  18%|█▊        | 9/50 [04:23<19:58, 29.23s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.33395394095868774\n",
      "Validation loss: 1.2183843887213506\n",
      "Validation Accuracy: 0.7525386912842791\n",
      "F1-Score: 0.628201945292912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  20%|██        | 10/50 [04:52<19:27, 29.19s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.27079844147418486\n",
      "Validation loss: 1.2506187774918296\n",
      "Validation Accuracy: 0.7554167797990768\n",
      "F1-Score: 0.6274304247006782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  22%|██▏       | 11/50 [05:21<18:59, 29.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.21697807029792757\n",
      "Validation loss: 1.303796730258248\n",
      "Validation Accuracy: 0.7559055118110236\n",
      "F1-Score: 0.6301563179521796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  24%|██▍       | 12/50 [05:50<18:29, 29.20s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.1838014739932436\n",
      "Validation loss: 1.3401407780069294\n",
      "Validation Accuracy: 0.7583491718707576\n",
      "F1-Score: 0.6355843334287724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  26%|██▌       | 13/50 [06:19<18:00, 29.20s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.1474974968216636\n",
      "Validation loss: 1.424536574970592\n",
      "Validation Accuracy: 0.7534618517512897\n",
      "F1-Score: 0.6361761530526412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  28%|██▊       | 14/50 [06:49<17:30, 29.18s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.1201435373813817\n",
      "Validation loss: 1.4316744190273862\n",
      "Validation Accuracy: 0.7575889220743959\n",
      "F1-Score: 0.6469978559934432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  30%|███       | 15/50 [07:18<17:01, 29.20s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.10154087514136777\n",
      "Validation loss: 1.4834134398084697\n",
      "Validation Accuracy: 0.759706760792832\n",
      "F1-Score: 0.6409606881675878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  32%|███▏      | 16/50 [07:47<16:32, 29.18s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.09026920736174691\n",
      "Validation loss: 1.527702889659188\n",
      "Validation Accuracy: 0.7560684224816725\n",
      "F1-Score: 0.6322445296973884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  34%|███▍      | 17/50 [08:16<16:03, 29.20s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.07608035212439118\n",
      "Validation loss: 1.5618869481664714\n",
      "Validation Accuracy: 0.7559055118110236\n",
      "F1-Score: 0.6396056236418036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  36%|███▌      | 18/50 [08:45<15:32, 29.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.07482431560867664\n",
      "Validation loss: 1.5792023485357112\n",
      "Validation Accuracy: 0.7561770295954385\n",
      "F1-Score: 0.645041040276935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  38%|███▊      | 19/50 [09:15<15:05, 29.20s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.06408327511709297\n",
      "Validation loss: 1.5735714182709202\n",
      "Validation Accuracy: 0.7606842248167255\n",
      "F1-Score: 0.6431707008467518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  40%|████      | 20/50 [09:44<14:34, 29.16s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.06340948510632823\n",
      "Validation loss: 1.5725411555983804\n",
      "Validation Accuracy: 0.7599239750203638\n",
      "F1-Score: 0.6369594088098733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  42%|████▏     | 21/50 [10:13<14:06, 29.20s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.05548128426413645\n",
      "Validation loss: 1.6208384651126284\n",
      "Validation Accuracy: 0.759652457235949\n",
      "F1-Score: 0.6368806979535654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  44%|████▍     | 22/50 [10:42<13:36, 29.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.056276644043850174\n",
      "Validation loss: 1.6135595151872346\n",
      "Validation Accuracy: 0.7569372793918001\n",
      "F1-Score: 0.642670653649202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  46%|████▌     | 23/50 [11:11<13:06, 29.11s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.045312836872075095\n",
      "Validation loss: 1.7170467268336902\n",
      "Validation Accuracy: 0.7442302470811838\n",
      "F1-Score: 0.6272931520941282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  48%|████▊     | 24/50 [11:40<12:36, 29.09s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.043436562614233204\n",
      "Validation loss: 1.6815656008142414\n",
      "Validation Accuracy: 0.7590551181102362\n",
      "F1-Score: 0.6367133200545341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  50%|█████     | 25/50 [12:09<12:06, 29.06s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.03373165805400773\n",
      "Validation loss: 1.7004632046728423\n",
      "Validation Accuracy: 0.7478142818354602\n",
      "F1-Score: 0.6263816598251767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  52%|█████▏    | 26/50 [12:38<11:37, 29.06s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.039675421377813276\n",
      "Validation loss: 1.7383535251472935\n",
      "Validation Accuracy: 0.7625305457507466\n",
      "F1-Score: 0.6418281096474093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  54%|█████▍    | 27/50 [13:07<11:09, 29.11s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.032219782415213005\n",
      "Validation loss: 1.734335933670853\n",
      "Validation Accuracy: 0.7603040999185446\n",
      "F1-Score: 0.6388584018818169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  56%|█████▌    | 28/50 [13:36<10:40, 29.10s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.028494198093981002\n",
      "Validation loss: 1.7503589789072673\n",
      "Validation Accuracy: 0.7581319576432256\n",
      "F1-Score: 0.6425671011569263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  58%|█████▊    | 29/50 [14:05<10:10, 29.07s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.030515191268712057\n",
      "Validation loss: 1.7728898254307834\n",
      "Validation Accuracy: 0.7619332066250339\n",
      "F1-Score: 0.6468461934620983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  60%|██████    | 30/50 [14:34<09:41, 29.06s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.02531300427984785\n",
      "Validation loss: 1.7537455757459004\n",
      "Validation Accuracy: 0.7621504208525658\n",
      "F1-Score: 0.6445000579493315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  62%|██████▏   | 31/50 [15:03<09:12, 29.05s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.025362633847786736\n",
      "Validation loss: 1.7951875563823816\n",
      "Validation Accuracy: 0.7581319576432256\n",
      "F1-Score: 0.6381979360205333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  64%|██████▍   | 32/50 [15:32<08:42, 29.04s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.021914293054688835\n",
      "Validation loss: 1.8339519825848667\n",
      "Validation Accuracy: 0.7594895465653\n",
      "F1-Score: 0.6375098608330084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  66%|██████▌   | 33/50 [16:01<08:13, 29.03s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.023967109620571136\n",
      "Validation loss: 1.8358457070408445\n",
      "Validation Accuracy: 0.761661688840619\n",
      "F1-Score: 0.6414637595972951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  68%|██████▊   | 34/50 [16:30<07:44, 29.04s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.024336897757497023\n",
      "Validation loss: 1.8527673627391006\n",
      "Validation Accuracy: 0.7599782785772468\n",
      "F1-Score: 0.6415148602312448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  70%|███████   | 35/50 [17:00<07:15, 29.04s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.02296860737260431\n",
      "Validation loss: 1.85028080145518\n",
      "Validation Accuracy: 0.7621504208525658\n",
      "F1-Score: 0.6434478121496936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  72%|███████▏  | 36/50 [17:29<06:46, 29.02s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.024866638496997908\n",
      "Validation loss: 1.874509040153388\n",
      "Validation Accuracy: 0.7575346185175129\n",
      "F1-Score: 0.6391656553080465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  74%|███████▍  | 37/50 [17:58<06:17, 29.04s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.01980953186108364\n",
      "Validation loss: 1.8486125071843464\n",
      "Validation Accuracy: 0.7613358674993213\n",
      "F1-Score: 0.6509357066907784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  76%|███████▌  | 38/50 [18:27<05:48, 29.02s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.01997701757566326\n",
      "Validation loss: 1.916942657846393\n",
      "Validation Accuracy: 0.7605756177029596\n",
      "F1-Score: 0.6412375096409503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  78%|███████▊  | 39/50 [18:56<05:19, 29.02s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.023907609403867162\n",
      "Validation loss: 1.8857930031689731\n",
      "Validation Accuracy: 0.7567743687211512\n",
      "F1-Score: 0.6360994500562593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  80%|████████  | 40/50 [19:25<04:50, 29.02s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.024587972636447485\n",
      "Validation loss: 1.8660660006783225\n",
      "Validation Accuracy: 0.7558512082541406\n",
      "F1-Score: 0.6472191154281649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  82%|████████▏ | 41/50 [19:54<04:21, 29.01s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0191026579087713\n",
      "Validation loss: 1.90902974208196\n",
      "Validation Accuracy: 0.7567200651642683\n",
      "F1-Score: 0.6374698441019772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  84%|████████▍ | 42/50 [20:23<03:52, 29.02s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.020114369300603303\n",
      "Validation loss: 1.9109041835322524\n",
      "Validation Accuracy: 0.7626391528645127\n",
      "F1-Score: 0.6416610800156384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  86%|████████▌ | 43/50 [20:52<03:23, 29.02s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.02114602301453212\n",
      "Validation loss: 1.885762131575382\n",
      "Validation Accuracy: 0.7522128699429813\n",
      "F1-Score: 0.6326747648017769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  88%|████████▊ | 44/50 [21:21<02:54, 29.02s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.018031769922482923\n",
      "Validation loss: 1.8921358368613503\n",
      "Validation Accuracy: 0.7558512082541406\n",
      "F1-Score: 0.6433485646096768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  90%|█████████ | 45/50 [21:50<02:25, 29.04s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.02091718146005984\n",
      "Validation loss: 1.9486093123753865\n",
      "Validation Accuracy: 0.755090958457779\n",
      "F1-Score: 0.6396228112148709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  92%|█████████▏| 46/50 [22:19<01:56, 29.03s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.023760351225395094\n",
      "Validation loss: 1.9474992390834924\n",
      "Validation Accuracy: 0.7568286722780342\n",
      "F1-Score: 0.6451139087153073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  94%|█████████▍| 47/50 [22:48<01:27, 29.03s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.015102688175499101\n",
      "Validation loss: 2.0581868489583335\n",
      "Validation Accuracy: 0.7527016019549281\n",
      "F1-Score: 0.640851809557822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  96%|█████████▌| 48/50 [23:17<00:58, 29.02s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.021138124542741218\n",
      "Validation loss: 1.9899327140865903\n",
      "Validation Accuracy: 0.7562313331523215\n",
      "F1-Score: 0.6370444116595388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  98%|█████████▊| 49/50 [23:46<00:29, 29.02s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.02112029598775376\n",
      "Validation loss: 1.9827114217209094\n",
      "Validation Accuracy: 0.7621504208525658\n",
      "F1-Score: 0.6422705595444577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 100%|██████████| 50/50 [24:15<00:00, 29.03s/it]\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.02190542119382316\n",
      "Validation loss: 1.9592859148979187\n",
      "Validation Accuracy: 0.7643225631278848\n",
      "F1-Score: 0.6461029378695063\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "epochs = 50\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "loss_fct = torch.nn.CrossEntropyLoss\n",
    "loss_fct_gpu = loss_fct(weight=weight.to('cuda'),ignore_index=tag2idx['X'])\n",
    "loss_fct_cpu = loss_fct(weight=weight.to('cpu'),ignore_index=tag2idx['X'])\n",
    "\n",
    "best_F1 = 0\n",
    "best_accuracy = 0\n",
    "best_model = None\n",
    "\n",
    "train_losses, validation_losses, accuracies, F1s = [],[],[],[]\n",
    "\n",
    "for _ in trange(epochs, desc=\"Epoch\"):\n",
    "    # TRAIN loop\n",
    "    model.train()\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # add batch to gpu\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # forward pass\n",
    "        \n",
    "        active = ((b_input_mask.view(-1) == 1) * (b_labels.view(-1) != tag2idx['X']))\n",
    "        logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "        active_logits = logits.view(-1, len(tag2idx))[active]\n",
    "        active_labels = b_labels.view(-1)[active]\n",
    "        loss = loss_fct_gpu(active_logits, active_labels)\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        # track train loss\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        model.zero_grad()\n",
    "    # print train loss per epoch\n",
    "    # print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "    # VALIDATION on validation set\n",
    "    model.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    predictions , true_labels = [], []\n",
    "    for batch in valid_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # tmp_eval_loss = model(b_input_ids, token_type_ids=None,\n",
    "            #                       attention_mask=b_input_mask, labels=b_labels)\n",
    "            logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "\n",
    "# original\n",
    "#         logits = logits.detach().cpu().numpy()\n",
    "#         label_ids = b_labels.to('cpu').numpy()\n",
    "#         predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
    "#         true_labels.append(label_ids)\n",
    "#         tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "#         eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "#revised\n",
    "        active = ((b_input_mask.view(-1) == 1) * (b_labels.view(-1) != tag2idx['X']))\n",
    "        active_logits = logits.view(-1, len(tag2idx))[active].cpu()\n",
    "        active_labels = b_labels.view(-1)[active].cpu()\n",
    "        loss = loss_fct_cpu(active_logits, active_labels)\n",
    "        pred_labels = np.argmax(active_logits, axis=1)\n",
    "        predictions.append(pred_labels)\n",
    "        true_labels.append(active_labels)\n",
    "        \n",
    "        \n",
    "        eval_loss += loss.item()\n",
    "        \n",
    "        nb_eval_examples += b_input_ids.size(0)\n",
    "        nb_eval_steps += 1\n",
    "    eval_loss = eval_loss/nb_eval_steps\n",
    "    tr_loss = tr_loss/nb_eval_steps\n",
    "    predictions = np.concatenate(predictions)\n",
    "    true_labels = np.concatenate(true_labels)\n",
    "    eval_accuracy = accuracy_score(true_labels, predictions, normalize=True, sample_weight=None)\n",
    "    F1 = f1_score(true_labels, predictions, average='macro')\n",
    "    print(\"Train loss: {}\".format(tr_loss))\n",
    "    print(\"Validation loss: {}\".format(eval_loss))\n",
    "    print(\"Validation Accuracy: {}\".format(eval_accuracy))\n",
    "    print(\"F1-Score: {}\".format(F1))\n",
    "    train_losses.append(tr_loss)\n",
    "    validation_losses.append(eval_loss)\n",
    "    accuracies.append(eval_accuracy)\n",
    "    F1s.append(F1)\n",
    "\n",
    "    if F1 > best_F1:\n",
    "        best_F1, best_accuracy, best_model = F1, eval_accuracy, deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "8p53wrmhJUtQ",
    "outputId": "e7047f7e-b729-414b-a081-689417bc6d60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1: 0.6509357066907784\n",
      "Best accuracy: 0.7613358674993213\n"
     ]
    }
   ],
   "source": [
    "print(\"Best F1: {}\".format(best_F1))\n",
    "print(\"Best accuracy: {}\".format(best_accuracy))\n",
    "\n",
    "with open(\"output\",\"w\") as f:\n",
    "  f.write(\"Best F1: {}\\n\".format(best_F1))\n",
    "  f.write(\"Best accuracy: {}\".format(best_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "sYAVkAWt-3qI",
    "outputId": "6f0ffbd1-1e8f-4f1c-98ae-39787bbd0518"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAacAAAEGCAYAAADBr1rTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n55xzaceDk3POubTz/31n8g5iIZf/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epoch = np.arange(1,epochs+1)\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.plot(epoch,train_losses,'b',label=\"train loss\")\n",
    "ax1.plot(epoch,validation_losses,'r',label=\"validation loss\")\n",
    "ax1.legend(loc=0)\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.set_xlim(1,epochs)\n",
    "ax1.set_ylim(0,None)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(epoch,accuracies,'k',label=\"accuracy\")\n",
    "ax2.plot(epoch,F1s,'g',label=\"F1 score\")\n",
    "ax2.legend(loc=2)\n",
    "ax2.set_ylabel('performance')\n",
    "# ax2.set_ylim(0.5,1)\n",
    "plt.savefig(\"GUM.png\",dpi=600)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BERT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
